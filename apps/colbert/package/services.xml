<?xml version="1.0" encoding="utf-8" ?>
<!-- Copyright Vespa.ai. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root. -->
<services version="1.0">

  <admin version="2.0">
    <configservers>
      <configserver hostalias="node0" />
      <configserver hostalias="node1" />
      <configserver hostalias="node2" />
    </configservers>
    <cluster-controllers>
      <cluster-controller hostalias="node0" jvm-options="-Xms32M -Xmx64M" /> <!-- jvm-options added only to shrink memory for testing - remove before real use -->
      <cluster-controller hostalias="node1" jvm-options="-Xms32M -Xmx64M" />
      <cluster-controller hostalias="node2" jvm-options="-Xms32M -Xmx64M" />
    </cluster-controllers>
    <slobroks>
      <slobrok hostalias="node0" />
      <slobrok hostalias="node1" />
      <slobrok hostalias="node2" />
    </slobroks>

    <adminserver hostalias="node3" />
  </admin>

  <container id="feed" version="1.0">
    <!-- See https://docs.vespa.ai/en/embedding.html#huggingface-embedder -->
    <component id="e5" type="hugging-face-embedder">
        <transformer-model url="https://huggingface.co/intfloat/e5-small-v2/resolve/main/model.onnx"/>
        <tokenizer-model url="https://huggingface.co/intfloat/e5-small-v2/raw/main/tokenizer.json"/>
    </component>

    <!-- See https://docs.vespa.ai/en/embedding.html#colbert-embedder -->
    <component id="colbert" type="colbert-embedder">
        <transformer-model url="https://huggingface.co/colbert-ir/colbertv2.0/resolve/main/model.onnx"/>
        <tokenizer-model url="https://huggingface.co/colbert-ir/colbertv2.0/raw/main/tokenizer.json"/>
    </component>

    <document-api />
    <document-processing/>
    <nodes>
      <node hostalias="node4"/>
      <node hostalias="node5"/>
    </nodes>
  </container>

  <container id="query" version="1.0">
    <!-- See https://docs.vespa.ai/en/embedding.html#huggingface-embedder -->
    <component id="e5" type="hugging-face-embedder">
        <transformer-model url="https://huggingface.co/intfloat/e5-small-v2/resolve/main/model.onnx"/>
        <tokenizer-model url="https://huggingface.co/intfloat/e5-small-v2/raw/main/tokenizer.json"/>
    </component>

    <!-- See https://docs.vespa.ai/en/embedding.html#colbert-embedder -->
    <component id="colbert" type="colbert-embedder">
        <transformer-model url="https://huggingface.co/colbert-ir/colbertv2.0/resolve/main/model.onnx"/>
        <tokenizer-model url="https://huggingface.co/colbert-ir/colbertv2.0/raw/main/tokenizer.json"/>
    </component>

    <search/>
    <nodes>
      <node hostalias="node6" />
      <node hostalias="node7" />
    </nodes>
  </container>

  <content id="music" version="1.0">
    <min-redundancy>2</min-redundancy>
    <documents>
        <document type="doc" mode="index" />
    </documents>
    <nodes>
      <node hostalias="node8" distribution-key="0" />
      <node hostalias="node9" distribution-key="1" />
    </nodes>
    <!-- because we are using the k3s local storage provider, the disk isn't dedicated to Vespa
         as it expects, so we need to increase the default limit from 0.75 so it doesn't think
         the index has become too large -->
    <tuning>
        <resource-limits>
            <disk>0.90</disk>
        </resource-limits>
    </tuning>
  </content>
</services>
